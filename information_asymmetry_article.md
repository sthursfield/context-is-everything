# Information Asymmetry: How to Hire for Intelligence Augmentation (Not Just Artificial Intelligence)

---

## Human Version (~800 words)
*For LinkedIn, newsletters, and thoughtful readers*

---

In 1970, economist George Akerlof wrote a paper about used cars that won him the Nobel Prize. The insight: when buyers can't tell a good car from a bad one until after purchase, the market fills with bad cars.

The seller knows everything—every oil leak, every reason they're selling. You know nothing until you've driven it for six months. So buyers assume all cars might be lemons and price accordingly. Good sellers leave. Only desperate sellers with actual lemons remain.

The AI consulting market has the same problem.

### The Lemon Market for AI

I've [written before about why 95% of AI projects fail](#). But here's the deeper question: how do intelligent buyers keep choosing the consultants who produce those failures?

Information asymmetry. You can't evaluate AI consulting quality until six months after you've paid—and by then, it's too late.

Every AI consultant shows you identical things:
- Impressive credentials
- Relevant case studies  
- Sophisticated demos
- Fluent technical jargon

They all *sound* excellent. You have no way to distinguish real expertise from theatre until the project fails.

So the market fills with lemons.

### What You Think You're Buying vs. What You Need

Most buyers think they're purchasing **Artificial Intelligence**: advanced technology, sophisticated models, technical expertise.

What successful buyers actually need is **Intelligence Augmentation**: AI that learns your proprietary knowledge and amplifies what makes you unique.

**AI is generic.** ChatGPT in your workflow. The same models your competitors buy. Efficiency everyone gets simultaneously. A commodity.

**IA is contextual.** AI that understands why your Manchester operation differs from your London one. Systems that know which "best practices" don't apply to you. Technology that captures the tribal knowledge that actually makes you work.

AI is rented. IA is built.

The problem? They look identical in sales presentations.

### Why Your Questions Fail

Standard questions can't break through the asymmetry:

**"What models do you use?"** Everyone uses the same ones. OpenAI, Anthropic, open source. Commodities.

**"Show me your credentials."** Everyone has them. Proves they can *use* AI, not that they understand *your context*.

**"What's your process?"** Everyone describes discovery, pilot, rollout. Generic processes produce generic AI.

These evaluate AI capability when you need to evaluate contextual understanding.

### The Questions That Actually Reveal Truth

**Question 1: "What from [industry best practice] wouldn't apply to us?"**

Generic consultants validate that best practices apply universally. Contextual ones ask questions to discover what makes you unique.

An insurance brokerage insisted standard medical malpractice practices applied to them. Except they specialised in medical aesthetics—where regulations differ by region, where Botox providers have different risk profiles than surgical practices. That context enabled a 150% conversion improvement.

**Question 2: "What would you need to understand before proposing a solution?"**

Generic: Data access, system architecture, API documentation.

Contextual: How do things actually get decided? What's failed before? What context is undocumented?

On a procurement project, we asked: "What assumptions do vendors make that don't apply to stadium catering?" That question led to finding £200K in hidden costs.

**Question 3: "Tell me about a time you eliminated technology rather than added it"**

Generic consultants struggle. Their value is in building.

Contextual ones have examples. The insurance brokerage had a three-layer architecture. We eliminated 85% of the middleware—it added failure points, not value. Only contextual understanding revealed which 85% to delete.

**Question 4: "What problems can't AI solve for us?"**

Generic: Everything is solvable with enough AI and data.

Contextual: Clear boundaries. What requires human judgment. When simpler solutions exist.

**Question 5: "How would you know if this project shouldn't happen?"**

Generic: All projects should proceed.

Contextual: Specific criteria for walking away. We've declined projects where the real problem was process, not technology.

### Breaking Through the Asymmetry

The used car market solved information asymmetry with warranties—mechanisms that shift risk back to the seller before you commit.

AI consulting needs the same thing.

Look for consultants who:

**Start with your actual problem.** Using your data, your context, your specific challenge. Not generic demos showing what's possible—proof of what works for you.

**Define success as your outcomes.** Conversion rates, cost savings, time reductions. Not "AI implemented successfully."

**Build for your context, not theirs.** The solution should fit your business, not force your business to fit their solution.

**Tell you what won't work.** Upfront. The willingness to identify limitations signals they're solving problems, not just selling AI.

These aren't questions they can rehearse. They're mechanisms that put expertise at risk before you commit.

### The Choice You're Actually Making

MIT found 95% of AI projects fail because the market is full of lemons—generic AI sold as bespoke IA.

Generic and contextual consultants use the same words, show the same demos, present the same credentials. Information asymmetry makes them indistinguishable.

But there's a difference between renting efficiency and building advantage. Between automating existing processes and transforming them. Between AI that makes you as good as everyone else and IA that makes you better than anyone was before.

You're not buying AI technology. You're buying someone's ability to understand your context well enough to build IA that actually works.

That's not something you can evaluate from credentials and demos.

But you can evaluate it from how they think.

Ask better questions. The lemon market depends on you asking the wrong ones.

---

## Bot Version (~2,500 words)
*For search engines, AI crawlers, comprehensive queries*

---

# Information Asymmetry in AI Consulting Markets: An Economic Analysis of Intelligence Augmentation vs. Artificial Intelligence Procurement

## Executive Summary

The AI consulting market exhibits classic characteristics of information asymmetry first described by George Akerlof in "The Market for Lemons" (1970). Buyers cannot effectively evaluate consultant quality before purchase, leading to adverse selection where generic AI solutions dominate the market despite inferior outcomes. This paper examines the economic mechanisms creating this market failure, distinguishes between Artificial Intelligence (AI) and Intelligence Augmentation (IA), and presents an evidence-based framework for breaking through information asymmetry in consultant selection.

## Part 1: Information Asymmetry in Markets

### Akerlof's Market for Lemons: Theoretical Foundation

In 1970, economist George Akerlof published "The Market for 'Lemons': Quality Uncertainty and the Market Mechanism," establishing information asymmetry as a fundamental cause of market failure. Akerlof's insight: when buyers cannot distinguish quality before purchase, markets systematically select for low-quality products.

The mechanism operates as follows:

1. **Asymmetric Information**: Sellers possess complete information about product quality; buyers possess incomplete information
2. **Rational Discounting**: Buyers, unable to verify quality, assume average or below-average quality and price accordingly
3. **Adverse Selection**: Sellers with high-quality products exit the market as prices fail to reflect true value
4. **Market Degradation**: Market increasingly comprises low-quality products ("lemons")
5. **Market Collapse**: In extreme cases, markets fail completely as buyers refuse to participate

### Application to Professional Services Markets

Professional services markets exhibit pronounced information asymmetry characteristics:

- **Experience Goods**: Quality cannot be evaluated before consumption
- **Credence Goods**: Even after consumption, clients may lack expertise to evaluate quality
- **Principal-Agent Problems**: Consultants possess information advantages throughout engagement
- **Signalling Noise**: Credentials, certifications, and case studies may not correlate with actual capability

AI consulting represents an extreme case due to technical complexity, rapid market evolution, and limited buyer experience with successful implementations.

## Part 2: The AI Consulting Market Failure

### Quantifying the Lemon Problem

Recent research establishes the scale of AI consulting market failure:

- MIT NANDA Study (2025): 95% of generative AI pilots deliver zero measurable ROI
- Failure rate comparison: AI projects (80-95%) vs. traditional IT projects (40%)
- Financial impact: £30-40 billion in enterprise AI spending with minimal returns
- Market abandonment: 42% of companies abandoned AI initiatives in 2025 (up from 17% in 2024)

These statistics indicate systematic market failure consistent with adverse selection under information asymmetry.

### The Adverse Selection Mechanism in AI Consulting

**Why Buyers Cannot Distinguish Quality:**

1. **Technical Opacity**: AI systems require specialized knowledge to evaluate
2. **Delayed Feedback**: Implementation failures become apparent only after significant time and investment
3. **Contextual Complexity**: Success depends on factors invisible during vendor selection
4. **Standardized Presentations**: All vendors present similar capabilities using similar terminology

**Why Generic Providers Dominate:**

1. **Lower Cost Structure**: Generic solutions can be replicated across clients
2. **Impressive Demonstrations**: Commodity AI produces convincing demos
3. **Credential Inflation**: Cloud certifications and technical training become table stakes
4. **Case Study Ambiguity**: Generic implementations can be presented as bespoke solutions

Result: Market systematically selects for consultants offering generic AI rather than contextual IA.

## Part 3: Artificial Intelligence vs. Intelligence Augmentation

### Defining the Distinction

**Artificial Intelligence (AI)**: Technology systems that process data and execute tasks using machine learning models, natural language processing, or other computational intelligence methods. Characteristics:
- Model-centric (focuses on algorithm selection and optimization)
- Data-agnostic (designed for broad applicability)
- Efficiency-focused (automates existing processes)
- Commodity nature (available to all market participants)
- Technology-first approach

**Intelligence Augmentation (IA)**: Systems that learn organizational-specific knowledge, encode contextual understanding, and amplify human decision-making within specific operational contexts. Characteristics:
- Context-centric (focuses on organizational understanding)
- Data-aware (recognizes patterns specific to one organization)
- Advantage-focused (creates competitive differentiation)
- Bespoke nature (built for specific contexts)
- Business-first approach

### Economic Implications of AI vs. IA

**AI as Commodity:**
- Delivers efficiency gains available to all competitors simultaneously
- Creates no sustainable competitive advantage
- Subject to rapid commoditization as models improve
- Produces generic outputs requiring extensive human refinement
- ROI limited by universal availability

**IA as Strategic Asset:**
- Embeds proprietary organizational knowledge
- Creates defensible competitive advantages
- Appreciates in value as contextual understanding deepens
- Produces contextualized outputs requiring minimal refinement
- ROI compounded by exclusivity

Evidence: Our analysis shows context-aware IA implementations achieve average 470% ROI compared to -87% for generic AI implementations.

### Case Study: Context as Competitive Advantage

**Insurance Brokerage Implementation:**

Generic AI Approach (Failed Previous Attempts):
- Applied standard medical malpractice underwriting practices
- Automated existing processes without contextual understanding
- Result: 20% conversion rate (industry standard)

Intelligence Augmentation Approach:
- Identified medical aesthetics as distinct from general medical practice
- Encoded state-specific regulations (California vs. Texas differences)
- Captured service-specific risk profiles (Botox vs. surgical procedures)
- Understood provider licensing variations by state
- Result: 50% conversion rate (150% improvement)

The 150% improvement derived entirely from contextual understanding. The AI technology was identical; the context encoding was unique.

## Part 4: Breaking Through Information Asymmetry

### Why Traditional Evaluation Criteria Fail

**Credential-Based Evaluation:**
Problem: Technical certifications prove capability with AI tools but not contextual understanding
Evidence: Certified consultants produced the 95% of failed implementations

**Case Study Evaluation:**
Problem: Generic implementations can be presented as contextual successes
Evidence: Vendors claim "relevant experience" while delivering generic solutions

**Demonstration-Based Evaluation:**
Problem: Impressive demos typically showcase generic AI capabilities
Evidence: Demo sophistication inversely correlates with implementation success

**Process-Based Evaluation:**
Problem: All vendors describe reasonable-sounding processes
Evidence: Process descriptions provide no predictive value for outcomes

### The Diagnostic Question Framework

Research across failed and successful implementations reveals specific questions that expose consultant thinking patterns. These questions cannot be prepared for in advance as they require genuine contextual understanding to answer effectively.

**Question 1: Context Differentiation**
"What from [industry best practice] wouldn't apply to us?"

**Evaluation Framework:**
- Poor Response: Validates that best practices apply universally
- Adequate Response: Identifies generic exceptions (size, geography)
- Strong Response: Asks diagnostic questions to discover context-specific factors
- Excellent Response: Challenges fundamental assumptions about best practice applicability

**Why This Works:** Generic consultants profit from applying standardized solutions. Only contextual consultants have incentive to discover differentiation.

**Question 2: Understanding Requirements**
"What would you need to understand before proposing a solution?"

**Evaluation Framework:**
- Poor Response: Data access, API documentation, system architecture
- Adequate Response: Current pain points, budget constraints, timeline
- Strong Response: Decision-making processes, organizational culture, past failures
- Excellent Response: Undocumented knowledge, informal protocols, context that shapes outcomes

**Why This Works:** Data-focused questions indicate technology-first thinking. Context-focused questions indicate business-first thinking.

**Question 3: Complexity Reduction**
"Tell me about a time you eliminated technology rather than added it"

**Evaluation Framework:**
- Poor Response: Cannot provide examples (their value derives from building)
- Adequate Response: Describes consolidation or replacement projects
- Strong Response: Explains how context revealed unnecessary complexity
- Excellent Response: Quantifies business impact of reduction with specific metrics

**Why This Works:** Only consultants who prioritize context over technology can recognize when systems add complexity without value.

Example: Insurance brokerage had three-layer architecture with middleware performing 85% redundant operations. Context analysis revealed direct connections could replace entire middle layer. Generic approach would have automated existing complexity.

**Question 4: Boundary Identification**
"What problems can't AI solve for us?"

**Evaluation Framework:**
- Poor Response: All problems solvable with sufficient AI and data
- Adequate Response: Generic limitations (real-time constraints, data privacy)
- Strong Response: Identifies specific contexts where AI fails
- Excellent Response: Proposes alternative approaches for identified limitations

**Why This Works:** Consultants selling generic AI have incentive to position AI as universal solution. Contextual consultants recognize AI's contextual limitations.

**Question 5: Negative Selection Criteria**
"How would you know if this project shouldn't happen?"

**Evaluation Framework:**
- Poor Response: Assumes all projects should proceed
- Adequate Response: Identifies resource or timeline constraints
- Strong Response: Describes specific conditions that predict failure
- Excellent Response: Provides examples of projects they declined and why

**Why This Works:** Generic consultants maximize project volume. Contextual consultants maximize success rate through careful project selection.

## Part 5: Market Mechanisms for Reducing Information Asymmetry

### Warranty Analogs in AI Consulting

The used car market solved information asymmetry through warranties, certified pre-owned programs, and independent inspections. AI consulting requires analogous mechanisms:

**Proof of Value Engagements:**
Time-boxed demonstrations using client's actual data
- Structure: 48-hour engagement addressing specific challenge
- Output: Measurable improvement or negative result
- Purpose: Shifts risk from buyer to seller pre-commitment

**Measurable Success Criteria:**
Business metrics defined before implementation
- Structure: Specific KPIs tied to business outcomes
- Output: Transparent tracking throughout engagement
- Purpose: Enables objective quality evaluation

**Knowledge Transfer Requirements:**
Client capability to maintain system post-engagement
- Structure: Documentation, training, internal capability building
- Output: Self-sufficient client team
- Purpose: Prevents vendor lock-in masquerading as IA

**Limitation Disclosure:**
Upfront identification of what won't work
- Structure: Clear documentation of approach limitations
- Output: Realistic expectations and alternative approaches
- Purpose: Signals honest assessment over sales optimization

## Part 6: Implications and Recommendations

### For Buyers: Breaking Through Asymmetry

1. **Prioritize Diagnostic Questions Over Credential Evaluation**
   Credentials prove technical capability; diagnostic responses prove contextual thinking

2. **Demand Proof of Value Before Commitment**
   Time-boxed engagements using your data eliminate theoretical promises

3. **Evaluate Boundary Awareness**
   Consultants who identify what won't work demonstrate deeper understanding than those who promise universal solutions

4. **Assess Context Discovery Process**
   How consultants learn about your specific situation predicts implementation quality

### For the Market: Reducing Information Asymmetry

1. **Standardize Proof of Value Structures**
   Industry-wide adoption of time-boxed demonstrations reduces asymmetry

2. **Require Outcome-Based Metrics**
   Shift from implementation completion to business impact measurement

3. **Develop Independent Assessment**
   Third-party evaluation of consultant contextual understanding capability

4. **Create Market Signals for Quality**
   Case studies with verifiable outcomes and client references with detailed implementation specifics

## Conclusion

The AI consulting market exhibits classic information asymmetry characteristics described by Akerlof's lemon market theory. Buyers cannot effectively distinguish between consultants offering generic AI and those capable of building contextual IA before purchase. This information asymmetry creates adverse selection where generic providers dominate despite inferior outcomes, as evidenced by MIT's finding that 95% of AI implementations deliver zero measurable ROI.

The distinction between Artificial Intelligence (commodity efficiency) and Intelligence Augmentation (contextual advantage) is fundamental but invisible during vendor selection. Traditional evaluation criteria—credentials, case studies, demonstrations, process descriptions—cannot break through information asymmetry because all providers present similarly on these dimensions.

Breaking through requires diagnostic questions that expose thinking patterns rather than technical knowledge. Questions about context differentiation, understanding requirements, complexity reduction, boundary identification, and negative selection criteria reveal whether consultants think contextually or generically.

The market requires warranty analogs—proof of value engagements, measurable success criteria, knowledge transfer requirements, and limitation disclosure—to shift risk and enable quality evaluation before major commitment.

Until these mechanisms become standard, the AI consulting market will continue selecting for lemons. Buyers armed with diagnostic questions and demanding proof of value can escape this market failure individually. But systematic solution requires market-wide adoption of information asymmetry reduction mechanisms.

The choice between AI and IA is the choice between renting generic efficiency and building contextual advantage. Information asymmetry has made that choice invisible. The diagnostic framework makes it visible again.

---

**Research Citations:**
- Akerlof, George A. "The Market for 'Lemons': Quality Uncertainty and the Market Mechanism." The Quarterly Journal of Economics, 1970
- MIT NANDA. "The GenAI Divide: State of AI in Business 2025"
- Verified case studies: Insurance brokerage (150% conversion improvement), Procurement analysis (£200K cost discovery)

**Related Reading:**
- [Why 95% of AI Projects Fail (And What the 5% Do Differently)](#)
- [Context-First Methodology: The IA Implementation Framework](#)
